{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFI-DF Unsupervised Recommender Example\n",
    "<i>Facililated by Josh Mason and Yousif Mansour, 9/22/2023</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is part of our preliminary algorithm research phase. \n",
    "\n",
    "At this point in the project, we have decided to stick with TF-IDF as it's the only purely unsupervised model availabe in Microsoft Recommenders.\n",
    "\n",
    "### 1. Load the Metadata from our local test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Import functions\n",
    "import pandas as pd\n",
    "from recommenders.models.tfidf.tfidf_utils import TfidfRecommender\n",
    "\n",
    "metadata = pd.read_csv(\"metadata.csv\") # TODO (file does not exist yet)\n",
    "print(\"Number of entries in metadata dataset: \" + str(len(metadata)))\n",
    "metadata.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Instantiate the recommender\n",
    "\n",
    "These are the following tokenization methods available out-of-the-box with this implementation:\n",
    "\n",
    "| tokenization_method | Description                                                                                                                      |\n",
    "|:--------------------|:---------------------------------------------------------------------------------------------------------------------------------|\n",
    "| 'none'              | No tokenization is applied. Each word is considered a token.                                                                     |\n",
    "| 'nltk'              | Simple stemming is applied using NLTK.                                                                                           |\n",
    "| 'bert'              | HuggingFace BERT word tokenization ('bert-base-cased') is applied.                                                               |\n",
    "| 'scibert'           | SciBERT word tokenization ('allenai/scibert_scivocab_cased') is applied.<br>This is recommended for scientific journal articles. |\n",
    "\n",
    "<i>Source: [Microsoft Recommender](https://github.com/recommenders-team/recommenders/blob/main/examples/00_quick_start/tfidf_covid.ipynb)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = TfidfRecommender(id_col='uid', tokenization_method='scibert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare text for use in the TFI-DF model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommenders_kernel",
   "language": "python",
   "name": "recommenders"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
